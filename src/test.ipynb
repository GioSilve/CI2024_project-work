{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import globals as gb\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import dataclass\n",
    "from tree import Tree, swap_subtrees, generate_initial_solution\n",
    "from utils import mse, sort_individuals\n",
    "from mutations import mutation\n",
    "from tree_node import TreeNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which problem to get input variables from by inserting the desired problem id as argument of the following function\n",
    "gb.initialize_globals_for_problem(2)\n",
    "\n",
    "POPULATION_SIZE = gb.PROBLEM_SIZE * 20\n",
    "OFFSPRING_SIZE = int(POPULATION_SIZE / 4)\n",
    "MAX_ITERATIONS = 10000 - gb.PROBLEM_SIZE * 2000 if gb.PROBLEM_SIZE < 5 else 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "- We treat a possible solution as a tree. The tree has attribute root, which is the root of the tree of class TreeNode and max_depth.\n",
    "- Generate random tree\n",
    "    - we need each variable at least once \n",
    "    - each variable has exactly one coefficient chosen as a random float number in the range [?, ?]\n",
    "    - each variable has exactly one unary operator\n",
    "    - unary operator is chosen as: 50% chance of \"\" (i.e. no change to the variable), 50% chance of choosing among all other unary operators\n",
    "        - check if the unary operator is appliable to the variable ->\n",
    "            ```\n",
    "            leaves_map = {}\n",
    "            for e in leaves:\n",
    "                available_unary_operators = [op for op in list(UNARY_OPERATORS.keys()) if op.is_applicable(e)]\n",
    "                chosen_unary_operator = 50% chance of \"\" (i.e. no change to the variable), 50% chance of choosing among [available_unary_operators]\n",
    "                leaves_map[e] = [chosen_unary_operator]\n",
    "            # leaves = [-2, 3]\n",
    "            # leaves_map = {-2: square, 3: log}\n",
    "            for e in leaves:\n",
    "                node = leaves_map[e]\n",
    "                node.left = null\n",
    "                node.right = e\n",
    "                # insert node to tree\n",
    "            ```\n",
    "    - number of leaves = nearest power of two greater than keys.length()\n",
    "    - number of actual leaves = [number of leaves] * 2\n",
    "    - number of coefficients = [number of leaves] - keys.length()\n",
    "    - number of binrary operators = total number of nodes in  tree with [number of leaves] leaves - [number of leaves]]\n",
    "    - validate tree\n",
    "    - if valid, return tree\n",
    "    - else, ?\n",
    "- Example:\n",
    "    - x.length() = 3\n",
    "    - number of leaves = 4\n",
    "    - number of actual leaves = 8\n",
    "    - number of coefficients = 1\n",
    "    - number of operands = 3\n",
    "\n",
    "    ```bash\n",
    "                    +\n",
    "            /                  \\\n",
    "            *                    +\n",
    "        /      \\           /        \\\n",
    "      u        1          1          u\n",
    "    /   \\    /   \\      /   \\       /  \\\n",
    "    nul  *  nul   *    nul    *     nul *\n",
    "    ```\n",
    "### EA approach\n",
    "- Individual is rapresented as a tree and a fitness\n",
    "    - fitness is a tuple of 2 values: (-mse, right_sign_100)\n",
    "        - right_sign_100 is the percentage of correct sign predictions\n",
    "        - mse is the mean squared error\n",
    "- Classic Genetic Programming\n",
    "    - Key elements \n",
    "    - Representation: tree structures\n",
    "    - Recombination: exchange of subtrees\n",
    "    - Mutation: random change in trees\n",
    "        - subtree mutation -> replace  entire subtree\n",
    "        - point  mutation -> change single node\n",
    "        - permutation -> exchange node right with left\n",
    "        - hoist -> take subtree and make it root\n",
    "        - expansion -> take random leaf and replace it with a new subtree\n",
    "        - collapse -> take a subtree and replace it with leaf\n",
    "    - Population model: generational\n",
    "    - Parent selection: fitness proportional\n",
    "    - Survivor selection: deterministic\n",
    "\n",
    "##next\n",
    "\n",
    "    - finish implementing mutations\n",
    "    - find way to reduce tree dimension\n",
    "    - add weights to opertors\n",
    "    - add check if fitness doesn't improve , stop early\n",
    "    - \n",
    "\n",
    "##problems\n",
    "    - overflow\n",
    "    - initial tree with 4xnodes has invalid values\n",
    "    - \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Individual:\n",
    "    genome: Tree\n",
    "    fitness: tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(sol: Tree):\n",
    "    y_computed = sol.root.evaluate_tree_from_node()\n",
    "    right_sign_100 = 100 * np.sum(np.sign(y_computed) == np.sign(gb.Y)) / len(gb.Y)\n",
    "    n_expected_leaves = int(2 ** np.ceil(np.log2(gb.PROBLEM_SIZE)))\n",
    "    expected_depth = np.log2(n_expected_leaves * 2) + 1\n",
    "    depth_penalty = (np.exp((sol.get_max_depth() / expected_depth)) - 1) if sol.get_max_depth() > expected_depth else 0\n",
    "    \n",
    "    leaves = [node.value for node in sol.get_leaves_nodes()]\n",
    "    missing_variables = [x for x in list(gb.VARIABLES_MAP.keys()) if x not in leaves]\n",
    "    missing_variables_penalty = (np.exp((len(missing_variables) / len(list(gb.VARIABLES_MAP.keys())))) - 1) if len(missing_variables) > len(list(gb.VARIABLES_MAP.keys())) else 0\n",
    "\n",
    "    return  -mse(y_computed, gb.Y) * (1 + depth_penalty + missing_variables_penalty), right_sign_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EA helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_selection(population: list[Individual], scores, worst_score):\n",
    "    # windowing    \n",
    "    scores_prime = [(s-worst_score) for s in scores]\n",
    "    total = sum(scores_prime)\n",
    "    # if all population doesn't have some score\n",
    "    if total != 0:\n",
    "        probabilities = [s/total for s in scores_prime]\n",
    "\n",
    "        parents = random.choices(population, probabilities, k=2)\n",
    "            \n",
    "        return parents[0], parents[1]\n",
    "    \n",
    "    return population[0], population[1]\n",
    "\n",
    "def xover(parent1, parent2)-> tuple[Tree, tuple]:\n",
    "    # reproduce\n",
    "    c1 = copy.deepcopy(parent1.genome)\n",
    "    c2 = copy.deepcopy(parent2.genome)\n",
    "\n",
    "    success = swap_subtrees(c1, c2)\n",
    "\n",
    "    c_fitness = fitness(c2)\n",
    "\n",
    "    if not success:\n",
    "        # mutation\n",
    "        mutation(c2)\n",
    "\n",
    "    return c2, c_fitness\n",
    "\n",
    "def tournament(population):\n",
    "    # generate a certain number of tournaments\n",
    "    n_tour = POPULATION_SIZE // 4\n",
    "    winners = []\n",
    "    # for each tournament find a winner for a portion of the population\n",
    "    for i in range(n_tour):\n",
    "        start =int( i*len(population)/n_tour)\n",
    "        end =int( (i+1)*len(population)/ n_tour)\n",
    "        p_i = population[start : end]\n",
    " \n",
    "        w_i = ea(p_i, 50,disable_print=True)\n",
    "        winners.append(w_i)\n",
    "    winners , scores = sort_individuals(winners)\n",
    "   \n",
    "    # get the best winner/s\n",
    "    # check if there are ties\n",
    "    best_score = np.max(scores)\n",
    "    return [winners[i] for i in range(len(winners)) if scores[i] == best_score]\n",
    "\n",
    "def fine_tuning(best: Individual):\n",
    "    genome = best.genome\n",
    "    best_fitness = best.fitness\n",
    "\n",
    "    n_no_inc = 0\n",
    "\n",
    "    leaves = genome.get_leaves_nodes()\n",
    "\n",
    "    max_iterations = MAX_ITERATIONS // 10\n",
    "    for i in range(max_iterations):\n",
    "        leaf = np.random.choice(leaves)\n",
    "        new_f = tune_constant(leaf,genome, best_fitness)\n",
    "\n",
    "        if new_f > best_fitness:\n",
    "            best_fitness = new_f\n",
    "            n_no_inc = 0\n",
    "        else:\n",
    "            n_no_inc += 1\n",
    "\n",
    "        if i % 5000 == 0 and i != 0:\n",
    "            print(best_fitness)\n",
    "\n",
    "        if n_no_inc > 1000:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    best.fitness = best_fitness\n",
    "\n",
    "\n",
    "def tune_constant(node: TreeNode, curr_genome, curr_fitness):\n",
    "    mutation_factor = 1.002\n",
    "    improve = True\n",
    "    direction_changed = False\n",
    "    while improve:\n",
    "        if node.value in gb.VARIABLES_MAP:\n",
    "            node.coefficient *= mutation_factor  # Modify costant\n",
    "            if round(node.coefficient)!=0: \n",
    "                node.coefficient = round(node.coefficient,4)\n",
    "        else:\n",
    "            node.value *= mutation_factor\n",
    "            if round(node.value)!=0: \n",
    "                node.value = round(node.value,4)\n",
    "                \n",
    "        new_mse, right_sign = fitness(curr_genome)\n",
    "        new_fitness = ( new_mse, right_sign)\n",
    "        # Update best solution\n",
    "        if new_fitness > curr_fitness:\n",
    "            curr_fitness = new_fitness\n",
    "            mutation_factor/=mutation_factor\n",
    "        else:\n",
    "            if node.value in gb.VARIABLES_MAP:\n",
    "                node.coefficient /= mutation_factor  # Revert change\n",
    "            else:\n",
    "                node.value /= mutation_factor\n",
    "            if not direction_changed:\n",
    "                direction_changed = True\n",
    "                mutation_factor = 0.998 # try to explore backward\n",
    "            else: \n",
    "                improve = False\n",
    "    \n",
    "    return curr_fitness    \n",
    "\n",
    "\n",
    "def ea(population, iterations=200, best=None, best_score=-1, disable_print=False):\n",
    "    scores = []\n",
    "    offsprings = []\n",
    "    worst_score = 0\n",
    "\n",
    "\n",
    "    # Initialize stopping condition for maximization problem\n",
    "    min_iterations = POPULATION_SIZE  # Wait for at least one generation\n",
    "    patience = int(iterations / 5)  # Wait for half a generation worth of iterations\n",
    "    stagnation_counter = 0\n",
    "  \n",
    "\n",
    "\n",
    "    for ind in population:\n",
    "        ind.fitness = fitness(ind.genome)\n",
    "    population, scores = sort_individuals(population)\n",
    "\n",
    "    for i in tqdm(range(iterations), disable=disable_print):\n",
    "    \n",
    "        for _ in range(OFFSPRING_SIZE):\n",
    "            parent1, parent2 = parent_selection(population, scores, worst_score)\n",
    "            # crossover\n",
    "            if random.random() < 0.7:\n",
    "                child, c_fitness = xover(parent1, parent2)\n",
    "        \n",
    "                offsprings.append(Individual(child, c_fitness))\n",
    "\n",
    "            # mutation\n",
    "            else :\n",
    "                # take a random individual and mutate it\n",
    "                ind = copy.deepcopy(random.choice([parent1,parent2]))\n",
    "\n",
    "                mutation(ind.genome)\n",
    "                # recompute fitness\n",
    "                ind.fitness = fitness(ind.genome)\n",
    "                offsprings.append(ind)\n",
    "\n",
    "        population.extend(offsprings)\n",
    "        offsprings = []\n",
    "        \n",
    "        # sort population according to score based on fitness         \n",
    "        population, scores = sort_individuals(population)\n",
    "        \n",
    "        score = scores[0] # best score in currrent population\n",
    "\n",
    "        \n",
    "        if i % patience == 0 and i > min_iterations:\n",
    "            # print(f\"iteration {i} mse {mse(population[0].genome.root.evaluate_tree_from_node(), gb.Y)}\")\n",
    "            if score > best_score*(1.01):\n",
    "                best = population[0]\n",
    "                best_score = score\n",
    "                stagnation_counter = 0\n",
    "            elif score <= best_score*1.01 and score >= best_score*0.99:\n",
    "                stagnation_counter+=1\n",
    "                if stagnation_counter == 3:\n",
    "                    print(\"Stopping early because not enough improvement found\")\n",
    "                    break\n",
    "            # put again the best one in population\n",
    "            else: \n",
    "                population.append(best)\n",
    "                population,scores = sort_individuals(population)\n",
    "                stagnation_counter = 0\n",
    "\n",
    "        # remove worst individual\n",
    "        population = population[:POPULATION_SIZE]\n",
    "        scores = scores[:POPULATION_SIZE]\n",
    "\n",
    "        worst_score = scores[OFFSPRING_SIZE-1] # if worst_score > scores[-1] else worst_score\n",
    "\n",
    "\n",
    "    print(f\"winner's mse {mse(population[0].genome.root.evaluate_tree_from_node(), gb.Y)} score: {scores[0]}\")\n",
    "\n",
    "    \n",
    "    return population[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = [Individual(generate_initial_solution(), 0) for i in range(POPULATION_SIZE)]\n",
    "offsprings = []\n",
    "\n",
    "# tournament -> use initial population\n",
    "winners = tournament(population)\n",
    "\n",
    "#generate population from winner/s\n",
    "population = []\n",
    "for w in winners:\n",
    "    for i in range(int(POPULATION_SIZE/len(winners))-1):\n",
    "        ind = copy.deepcopy(w)\n",
    "\n",
    "        mutation(ind.genome)\n",
    "        # recompute fitness\n",
    "        ind.fitness = fitness(ind.genome) \n",
    "        population.append(ind)\n",
    "    population.append(w)\n",
    "\n",
    "\n",
    "population, scores = sort_individuals(population)\n",
    "\n",
    "# ea\n",
    "result = ea(population, MAX_ITERATIONS, population[0], scores[0])\n",
    "\n",
    "# fine tuning of constants\n",
    "fine_tuning(result)\n",
    "\n",
    "print(f\"Best individual mse: {mse(result.genome.root.evaluate_tree_from_node(), gb.Y)}\")\n",
    "print(\"Best individual has formula:\")\n",
    "result.genome.print_tree()\n",
    "print(\"Best individual has formula:\")\n",
    "result.genome.draw_tree() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
